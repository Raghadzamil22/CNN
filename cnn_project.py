# -*- coding: utf-8 -*-
"""CNN.project

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/144BAedbR2I_rTSPbIgsYiZyAhdj75zfl
"""

from keras.models import Sequential
from keras.layers import Convolution2D
from keras.layers import MaxPooling2D
from keras.layers import Flatten
from keras.layers import Dense
from keras.models import Sequential
from keras.layers import Conv2D, Activation, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization
from keras.preprocessing.image import ImageDataGenerator
from keras.optimizers import Adam
from keras.callbacks import EarlyStopping, ReduceLROnPlateau
import matplotlib.pyplot as plt
from tensorflow.keras.optimizers import AdamW
from tensorflow.keras.preprocessing import image
from keras.models import load_model
from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, confusion_matrix
import os
from PIL import Image
import tensorflow as tf
import cv2
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
import warnings
warnings.filterwarnings("ignore")

from google.colab import drive
drive.mount('/content/drive')

img_size = 150
labels = ['PNEUMONIA', 'NORMAL']
def get_training_data(data_dir):
    data = []
    for label in labels:
        path = os.path.join(data_dir, label)
        class_num = labels.index(label)
        for img in os.listdir(path):
            try:
                img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)
                resized_arr = cv2.resize(img_arr, (img_size, img_size))
                data.append([resized_arr, class_num])
            except Exception as e:
                print(e)

    return np.array(data, dtype=object)

train = get_training_data('/content/drive/MyDrive/Colab Notebooks/CNN/train')
val = get_training_data('/content/drive/MyDrive/Colab Notebooks/CNN/val')
test = get_training_data('/content/drive/MyDrive/Colab Notebooks/CNN/test')

print('train_shape:',train.shape)
print('-------')
print('val_shape:',val.shape)
print('-------')
print('test_shape:',test.shape)

lis = []
for i in train:
    if(i[1] == 0):
        lis.append("pneumonia")
    else:
        lis.append("normal")
sns.countplot(lis)

plt.figure(figsize = (5,5))
plt.imshow(train[0][0], cmap='gist_heat')
plt.title(labels[train[0][1]])

plt.figure(figsize = (5,5))
plt.imshow(train[-1][0], cmap='gist_heat')
plt.title(labels[train[-1][1]])

from keras.applications import VGG16
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.optimizers import Adamax

base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

for layer in base_model.layers:
    layer.trainable = False

model = Sequential([
    base_model,
    Flatten(),
    Dense(256, activation='relu'),
    Dropout(0.5),
    Dense(2, activation='sigmoid')
])

opt = Adamax(learning_rate=0.0001,weight_decay=1e-4)
model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])

model.summary()

image_size = (224, 224)
batch_size = 32
train_datagen = ImageDataGenerator(
    rescale=1.0/255.0,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    vertical_flip=True
)


train_dir = '/content/drive/MyDrive/Colab Notebooks/CNN/train'

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=image_size,
    batch_size=batch_size,
    shuffle=True
)

val_datagen = ImageDataGenerator(
    rescale=1.0/255.0
)


val_dir = '/content/drive/MyDrive/Colab Notebooks/CNN/val'
val_generator = val_datagen.flow_from_directory(
    val_dir,
    target_size=image_size,
    batch_size=batch_size,
    shuffle=False

)

es = EarlyStopping(monitor='val_loss', mode='min', patience=10, restore_best_weights=True)
rlrp= ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6)
history = model.fit(train_generator, epochs=50, validation_data=val_generator, callbacks=[es,rlrp], verbose=1)

model.save('model.cnn1')

model = load_model('model.cnn1')

batch_size=32
test_datagen = ImageDataGenerator(
    rescale=1.0/255.0,
    featurewise_center=True,
    featurewise_std_normalization=True,
)

test_dir = '/content/drive/MyDrive/Colab Notebooks/CNN/test'
test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=image_size,
    batch_size=batch_size,
    shuffle=False
)

predictions = model.predict(test_generator)
predictions = np.argmax(predictions, axis=1)

accuracy = accuracy_score(test_generator.classes, predictions)
print('Accuracy:', accuracy*100)

f1 = f1_score(test_generator.classes, predictions)
print('F1:', f1*100)

recall = recall_score(test_generator.classes, predictions)
print('Recall:', recall*100)

precision = precision_score(test_generator.classes, predictions)
print('Precision:', precision*100)

cm = confusion_matrix(test_generator.classes, predictions)
print('Confusion Matrix:')
sns.heatmap(cm, annot=True, fmt="d",)

model = load_model('model.cnn1')
image_size = (224, 224)


def preprocess_image(img_path):
    img = image.load_img(img_path, target_size=image_size)
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array = img_array / 255.0
    return img_array

def classify_image(img_array):
    prediction = model.predict(img_array)
    label = "pneumonia" if prediction[0][1] > 0.5 else "normal"
    return label


img_path_normal = '/content/drive/MyDrive/Colab Notebooks/CNN/test/NORMAL/IM-0001-0001.jpeg'
img_path_pneumonia = '/content/drive/MyDrive/Colab Notebooks/CNN/test/PNEUMONIA/person100_bacteria_475.jpeg'

img_array_normal = preprocess_image(img_path_normal)
img_array_pneumonia = preprocess_image(img_path_pneumonia)


label_normal = classify_image(img_array_normal)
label_pneumonia = classify_image(img_array_pneumonia)

print(f'The image is : {label_normal}')
print(f'The image is : {label_pneumonia}')